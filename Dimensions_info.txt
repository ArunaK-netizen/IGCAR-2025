This is the encoded image shape: torch.Size([1, 16, 128, 128])
shape of the encoded image without noise: torch.Size([1, 16, 128, 128])
shape of the noise x: torch.Size([1, 16, 128, 128])
encoded image with noise: torch.Size([1, 16, 128, 128])
patches group torch.Size([1, 4096, 64])
prompt after t5 encoding: torch.Size([1, 256, 512])
#encoded image after patches: torch.Size([1, 4096, 64])
shape of dragon embedding: torch.Size([1, 256, 512])
shape of dragon token embedding: torch.Size([512])
shape of rock embedding: torch.Size([1, 256, 512])
shape of rock token embedding: torch.Size([512])
shape of sky embedding: torch.Size([1, 256, 512])
shape of sky token embedding: torch.Size([512])
shape of sun embedding: torch.Size([1, 256, 512])
shape of sun token embedding: torch.Size([512])
shape of clouds embedding: torch.Size([1, 256, 512])
shape of clouds token embedding: torch.Size([512])
all concepts embeddings: torch.Size([1, 5, 512])
concept embeddings before reshaping: torch.Size([1, 5, 512])
concept ids before reshaping: torch.Size([1, 5, 3])
concept vec before reshaping: torch.Size([1, 768])
concept embeddeds after reshaping: torch.Size([1, 5, 512])
concept ids after reshaping: torch.Size([1, 5, 3])
concept_vec after reshaping: torch.Size([1, 768])